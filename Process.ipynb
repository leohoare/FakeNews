{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Body ID                                        articleBody  \\\n",
      "0        0  A small meteorite crashed into a wooded area i...   \n",
      "1        0  A small meteorite crashed into a wooded area i...   \n",
      "2        0  A small meteorite crashed into a wooded area i...   \n",
      "3        0  A small meteorite crashed into a wooded area i...   \n",
      "4        0  A small meteorite crashed into a wooded area i...   \n",
      "5        0  A small meteorite crashed into a wooded area i...   \n",
      "6        0  A small meteorite crashed into a wooded area i...   \n",
      "7        0  A small meteorite crashed into a wooded area i...   \n",
      "8        0  A small meteorite crashed into a wooded area i...   \n",
      "9        0  A small meteorite crashed into a wooded area i...   \n",
      "\n",
      "                                            Headline     Stance  \n",
      "0  Soldier shot, Parliament locked down after gun...  unrelated  \n",
      "1  Tourist dubbed ‘Spider Man’ after spider burro...  unrelated  \n",
      "2  Luke Somers 'killed in failed rescue attempt i...  unrelated  \n",
      "3   BREAKING: Soldier shot at War Memorial in Ottawa  unrelated  \n",
      "4  Giant 8ft 9in catfish weighing 19 stone caught...  unrelated  \n",
      "5  Enormous 20-stone catfish caught with fishing ...  unrelated  \n",
      "6  Italian catches huge wels catfish; is it a rec...  unrelated  \n",
      "7  Not coming to a store near you: The pumpkin sp...  unrelated  \n",
      "8  One gunman killed in shooting on Parliament Hi...  unrelated  \n",
      "9             Soldier shot at war memorial in Canada  unrelated  \n"
     ]
    }
   ],
   "source": [
    "''' define Feature class '''\n",
    "%run Features.ipynb\n",
    "features = Features('./DefaultFiles/train_bodies.csv','./DefaultFiles/train_stances.csv')\n",
    "print(features.df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    For downloading for nltk\n",
    "    import \n",
    "    on first time download the following packages\n",
    "'''\n",
    "import nltk\n",
    "# nltk.download()\n",
    "# d (Download) then enter 'punkt', wordnet', 'stopwords' (individually)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.corpus import wordnet, stopwords\n",
    "import re\n",
    "\n",
    "'''\n",
    "    Process involves\n",
    "    1. Split into sentences\n",
    "    2. Split into words i.e [[word,word],[word,word,word]]\n",
    "    3. Stem - chop of ends\n",
    "    4. Lemmatise - remove inflection endings and return to base citionary\n",
    "    5. remove stopwards\n",
    "    6. only take words containing only letters\n",
    "'''\n",
    "def process( text ):\n",
    "    out = []\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    stemmer = PorterStemmer()\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    for sentence in sent_tokenize(text):\n",
    "        withoutStop = []\n",
    "        for word in word_tokenize(sentence):\n",
    "            word = word.strip()\n",
    "            word = stemmer.stem(word)\n",
    "            word = lemmatizer.lemmatize(word, wordnet.VERB)\n",
    "            # major speed gain only testing for letters\n",
    "            word = word.replace(\"n't\", 'not')\n",
    "            word = word.replace(\"'m\", 'am')\n",
    "            word = word.replace(\"'ve'\", 'have')\n",
    "            word = word.replace(\"'d\", 'would')\n",
    "            word = word.replace(\"'ll\", \"will\")\n",
    "            if word != '' and word.isalpha():\n",
    "                withoutStop.append(word.lower())\n",
    "        out.append(withoutStop)\n",
    "    return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A small meteorite crashed into a wooded area in Nicaragua\\'s capital of Managua overnight, the government said Sunday. Residents reported hearing a mysterious boom that left a 16-foot deep crater near the city\\'s airport, the Associated Press reports. \\n\\nGovernment spokeswoman Rosario Murillo said a committee formed by the government to study the event determined it was a \"relatively small\" meteorite that \"appears to have come off an asteroid that was passing close to Earth.\" House-sized asteroid 2014 RC, which measured 60 feet in diameter, skimmed the Earth this weekend, ABC News reports. \\nMurillo said Nicaragua will ask international experts to help local scientists in understanding what happened.\\n\\nThe crater left by the meteorite had a radius of 39 feet and a depth of 16 feet,  said Humberto Saballos, a volcanologist with the Nicaraguan Institute of Territorial Studies who was on the committee. He said it is still not clear if the meteorite disintegrated or was buried.\\n\\nHumberto Garcia, of the Astronomy Center at the National Autonomous University of Nicaragua, said the meteorite could be related to an asteroid that was forecast to pass by the planet Saturday night.\\n\\n\"We have to study it more because it could be ice or rock,\" he said.\\n\\nWilfried Strauch, an adviser to the Institute of Territorial Studies, said it was \"very strange that no one reported a streak of light. We have to ask if anyone has a photo or something.\"\\n\\nLocal residents reported hearing a loud boom Saturday night, but said they didn\\'t see anything strange in the sky.\\n\\n\"I was sitting on my porch and I saw nothing, then all of a sudden I heard a large blast. We thought it was a bomb because we felt an expansive wave,\" Jorge Santamaria told The Associated Press.\\n\\nThe site of the crater is near Managua\\'s international airport and an air force base. Only journalists from state media were allowed to visit it.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = features.df.iloc[0]['articleBody']\n",
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a small meteorit crash into a wood area in nicaragua capit of managua overnight the govern say sunday\n",
      "resid report hear a mysteri boom that leave a deep crater near the citi airport the associ press report\n",
      "govern spokeswoman rosario murillo say a committe form by the govern to studi the event determin it wa a rel small meteorit that appear to have come off an asteroid that wa pass close to earth\n",
      "asteroid rc which measur feet in diamet skim the earth thi weekend abc new report\n",
      "murillo say nicaragua will ask intern expert to help local scientist in understand what happen\n",
      "the crater leave by the meteorit have a radiu of feet and a depth of feet say humberto saballo a volcanologist with the nicaraguan institut of territori studi who wa on the committe\n",
      "he say it be still not clear if the meteorit disintegr or wa buri\n",
      "humberto garcia of the astronomi center at the nation autonom univers of nicaragua say the meteorit could be relat to an asteroid that wa forecast to pass by the planet saturday night\n",
      "we have to studi it more becaus it could be ice or rock he say\n",
      "wilfri strauch an advis to the institut of territori studi say it wa veri strang that no one report a streak of light\n",
      "we have to ask if anyon ha a photo or someth\n",
      "local resid report hear a loud boom saturday night but say they do not see anyth strang in the sky\n",
      "i wa sit on my porch and i saw noth then all of a sudden i hear a larg blast\n",
      "we think it wa a bomb becaus we felt an expans wave jorg santamaria tell the associ press\n",
      "the site of the crater be near managua intern airport and an air forc base\n",
      "onli journalist from state media be allow to visit it\n"
     ]
    }
   ],
   "source": [
    "for sentence in process( example ):\n",
    "    print(\" \".join(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total rows:  49972\n",
      "processed row:  0  time taken:: 0.04  seconds\n",
      "processed row:  1000  time taken:: 31.99  seconds\n",
      "processed row:  2000  time taken:: 55.79  seconds\n",
      "processed row:  3000  time taken:: 80.17  seconds\n",
      "processed row:  4000  time taken:: 102.48  seconds\n",
      "processed row:  5000  time taken:: 127.3  seconds\n",
      "processed row:  6000  time taken:: 146.84  seconds\n",
      "processed row:  7000  time taken:: 173.4  seconds\n",
      "processed row:  8000  time taken:: 191.21  seconds\n",
      "processed row:  9000  time taken:: 215.94  seconds\n",
      "processed row:  10000  time taken:: 231.97  seconds\n",
      "processed row:  11000  time taken:: 248.22  seconds\n",
      "processed row:  12000  time taken:: 264.3  seconds\n",
      "processed row:  13000  time taken:: 284.35  seconds\n",
      "processed row:  14000  time taken:: 307.57  seconds\n",
      "processed row:  15000  time taken:: 329.67  seconds\n",
      "processed row:  16000  time taken:: 345.47  seconds\n",
      "processed row:  17000  time taken:: 365.84  seconds\n",
      "processed row:  18000  time taken:: 383.22  seconds\n",
      "processed row:  19000  time taken:: 403.41  seconds\n",
      "processed row:  20000  time taken:: 420.52  seconds\n",
      "processed row:  21000  time taken:: 437.69  seconds\n",
      "processed row:  22000  time taken:: 454.11  seconds\n",
      "processed row:  23000  time taken:: 475.09  seconds\n",
      "processed row:  24000  time taken:: 497.85  seconds\n",
      "processed row:  25000  time taken:: 517.2  seconds\n",
      "processed row:  26000  time taken:: 533.06  seconds\n",
      "processed row:  27000  time taken:: 547.76  seconds\n",
      "processed row:  28000  time taken:: 570.45  seconds\n",
      "processed row:  29000  time taken:: 587.23  seconds\n",
      "processed row:  30000  time taken:: 605.14  seconds\n",
      "processed row:  31000  time taken:: 622.15  seconds\n",
      "processed row:  32000  time taken:: 638.5  seconds\n",
      "processed row:  33000  time taken:: 667.22  seconds\n",
      "processed row:  34000  time taken:: 689.02  seconds\n",
      "processed row:  35000  time taken:: 705.65  seconds\n",
      "processed row:  36000  time taken:: 730.24  seconds\n",
      "processed row:  37000  time taken:: 760.31  seconds\n",
      "processed row:  38000  time taken:: 779.43  seconds\n",
      "processed row:  39000  time taken:: 799.46  seconds\n",
      "processed row:  40000  time taken:: 820.23  seconds\n",
      "processed row:  41000  time taken:: 845.83  seconds\n",
      "processed row:  42000  time taken:: 867.05  seconds\n",
      "processed row:  43000  time taken:: 890.2  seconds\n",
      "processed row:  44000  time taken:: 916.44  seconds\n",
      "processed row:  45000  time taken:: 934.41  seconds\n",
      "processed row:  46000  time taken:: 954.99  seconds\n",
      "processed row:  47000  time taken:: 972.46  seconds\n",
      "processed row:  48000  time taken:: 992.43  seconds\n",
      "processed row:  49000  time taken:: 1040.76  seconds\n"
     ]
    }
   ],
   "source": [
    "''' Takes some time to completely process  ~ 12 minutes on my pc'''\n",
    "import time\n",
    "start_time = time.time()\n",
    "print(\"total rows: \", len(features.df))\n",
    "\n",
    "features.df['headProcessed'] = ''\n",
    "features.df['bodyProcessed'] = ''\n",
    "headProcessed = features.df.columns.get_loc(\"headProcessed\")\n",
    "bodyProcessed = features.df.columns.get_loc(\"bodyProcessed\")\n",
    "for index, row in features.df.iterrows():\n",
    "    ''' by replacing outer join you can regain sentence structure if desired '''\n",
    "    features.df.iat[index, headProcessed] = \" \".join(\" \".join(sent) for sent in process(row['Headline']))\n",
    "    features.df.iat[index, bodyProcessed] = \" \".join(\" \".join(sent) for sent in process(row['articleBody']))\n",
    "    if index % 1000 == 0:\n",
    "        print(\"processed row: \", index, \" time taken::\", round(time.time()-start_time, 2), \" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.df.to_csv('dataProcessed.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total rows:  25413\n",
      "processed row:  0  time taken:: 0.02  seconds\n",
      "processed row:  1000  time taken:: 17.45  seconds\n",
      "processed row:  2000  time taken:: 44.77  seconds\n",
      "processed row:  3000  time taken:: 62.88  seconds\n",
      "processed row:  4000  time taken:: 81.8  seconds\n",
      "processed row:  5000  time taken:: 103.29  seconds\n",
      "processed row:  6000  time taken:: 124.16  seconds\n",
      "processed row:  7000  time taken:: 142.55  seconds\n",
      "processed row:  8000  time taken:: 160.21  seconds\n",
      "processed row:  9000  time taken:: 183.49  seconds\n",
      "processed row:  10000  time taken:: 205.65  seconds\n",
      "processed row:  11000  time taken:: 229.53  seconds\n",
      "processed row:  12000  time taken:: 244.02  seconds\n",
      "processed row:  13000  time taken:: 265.63  seconds\n",
      "processed row:  14000  time taken:: 286.03  seconds\n",
      "processed row:  15000  time taken:: 302.01  seconds\n",
      "processed row:  16000  time taken:: 317.28  seconds\n",
      "processed row:  17000  time taken:: 335.89  seconds\n",
      "processed row:  18000  time taken:: 357.57  seconds\n",
      "processed row:  19000  time taken:: 375.02  seconds\n",
      "processed row:  20000  time taken:: 396.72  seconds\n",
      "processed row:  21000  time taken:: 416.86  seconds\n",
      "processed row:  22000  time taken:: 430.52  seconds\n",
      "processed row:  23000  time taken:: 444.93  seconds\n",
      "processed row:  24000  time taken:: 461.23  seconds\n",
      "processed row:  25000  time taken:: 475.52  seconds\n"
     ]
    }
   ],
   "source": [
    "features = Features('./DefaultFiles/test_bodies.csv','./DefaultFiles/test_stances_unlabeled.csv')\n",
    "import time\n",
    "start_time = time.time()\n",
    "print(\"total rows: \", len(features.df))\n",
    "\n",
    "features.df['headProcessed'] = ''\n",
    "features.df['bodyProcessed'] = ''\n",
    "headProcessed = features.df.columns.get_loc(\"headProcessed\")\n",
    "bodyProcessed = features.df.columns.get_loc(\"bodyProcessed\")\n",
    "for index, row in features.df.iterrows():\n",
    "    ''' by replacing outer join you can regain sentence structure if desired '''\n",
    "    features.df.iat[index, headProcessed] = \" \".join(\" \".join(sent) for sent in process(row['Headline']))\n",
    "    features.df.iat[index, bodyProcessed] = \" \".join(\" \".join(sent) for sent in process(row['articleBody']))\n",
    "    if index % 1000 == 0:\n",
    "        print(\"processed row: \", index, \" time taken::\", round(time.time()-start_time, 2), \" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.df.to_csv('testProcessed.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
